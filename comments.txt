В requirements.txt лучше указывать конкретные версии для которых код запускался. Это связано с тем, что по умолчанию устанавливается последняя версия и это может привести в неработоспособности кода, например, если было изменение синтаксиса, доступных методов и т. д.
Подробнее: https://learnpython.com/blog/python-requirements-file/
==================
Советую использовать pydantic. Это довольно полезный инструмент позволяющий выполнять проверку данных. Дополнительно можно посмотреть: https://vc.ru/u/1389654-machine-learning/592815-vvedenie-v-pydantic-moshchnaya-proverka-dannyh-dlya-vashih-rest-api-2023
=====================

12/10
8 row
ирония великая
17-00

Архитектура приложения представлена в файле sp9_project_arch.png. Состоит из 3-х сервисов. 
    1)stg_service
    2)dds_service
    3)cdm_service

Программный код и скрипты развертывания всех сервисов - в каталоге /solution

.env - файл с переменными окружения для всех сервисов
comments.txt - этот файл
docker-compose.yaml - файл для докера со всеми 3-мя сервисами

kafka-topics:
    order-service_orders # входящий топик 1-ого сервиса
    stg-service-orders # исходящий  топик 1-ого сервиса
    dds-service-orders # исходяший  топик 2-ого сервиса

входящий топик 1-ого сервиса заполняется данными "извне" приложения
исходящий топик 1-ого сервиса является входящим для 2-ого
исходяший топик 2-ого сервиса является входящим для 3-его
исходящего топика для 3-его сервиса нет

сервисы 1 и 2 считывают данные из соответствющих входящих топиков, обрабатывают их и сохраняют данные в
 соответствющих исходящих топиках
 таблицах БД Postgre соотв. схем

сервис 3 считывает данные из входящего топика, обрабатывает их и сохраняет результат в БД Postgre

логика обработки сосредоточена в файлах 
\solution\<имя_сервиса>\<имя_сервиса(3)_loader\<имя_сервиса(3)_message_processor_job.py
В этих файлах выполяется
 публикация в исходящий топик (метод self._producer.produce)
 сохранение в таблицах БД (методы класса в файлах \solution\<имя_сервиса>\<имя_сервиса(3)_loader\repository\<имя_сервиса(3)_repository.py

Центральный файл каждого сервиса - app.py
В нем выполняется
 чтение переменных окружения, определенных для сервиса
 запуск метода run соответствуюшего класса в фоновом режиме, каждые DEFAULT_JOB_INTERVAL секунд
 запуск flask-приложения

Метод run считывает данные, запись-за-записью из входящего kafka-топика порциями по batch_size записей
для этого используется self._consumer.consume()

в 1-м сервисе метод run "обогащает" данные kafka-топика информацией из Redis, сохраняет как-есть в stg-таблице, формирует payload заказа,  и отправляет в исходящий топик

входящее сообщение (пример)
# {
#     "object_id": 322519,
#     "object_type": "order",
#     "payload": {
#         "id": 322519,
#         "date": "2022-11-19 16:06:36",
#         "cost": 300,
#         "payment": 300,
#         "status": "CLOSED",
#         "restaurant": {
#             "id": "626a81cfefa404208fe9abae",
#             "name": "Кофейня №1"
#         },
#         "user": {
#             "id": "626a81ce9a8cd1920641e296",
#             "name": "Котова Ольга Вениаминовна"
#         },
#         "products": [
#             {
#                 "id": "6276e8cd0cf48b4cded00878",
#                 "price": 180,
#                 "quantity": 1,
#                 "name": "РОЛЛ С ТОФУ И ВЯЛЕНЫМИ ТОМАТАМИ",
#                 "category": "Выпечка"
#             },
#             {
#                 "id": "6276e8cd0cf48b4cded0086c",
#                 "price": 60,
#                 "quantity": 2,
#                 "name": "ГРИЛАТА ОВОЩНАЯ ПО-МЕКСИКАНСКИ",
#                 "category": "Закуски"
#             }
#         ]
#     }
# }

Исходящее сообщение (шаблон)
    dst_msg = {
        "object_id": msg["object_id"],
        "object_type": "order",
        "payload": {
            "id": msg["object_id"],
            "date": order["date"],
            "cost": order["cost"],
            "payment": order["payment"],
            "status": order["final_status"],
            "restaurant": self._format_restaurant(restaurant_id, restaurant_name),
            "user": self._format_user(user_id, user_name, user_login),
            "products": self._format_items(order["order_items"], restaurant)
        }
    }

во 2-м сервисе метод run получает сообщение, заполняет dds-таблицы хранилища по архитектуре Data Vault, формирует payload для 2-витрин и отправляет в исходящий kafka-топик

в 3-м сервисе метод run получает сообщение, определяет, в какую cdm-витрину ее записать и записывает.

Dashboard не сделал. Времени не хватает :(